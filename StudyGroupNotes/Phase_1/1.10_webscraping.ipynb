{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc6d2e4",
   "metadata": {},
   "source": [
    "## Phase 1.10\n",
    "\n",
    "# Webscraping\n",
    "\n",
    "## DOM & HTML\n",
    "\n",
    "> *Web pages can be represented by the objects that comprise their structure and content. This representation is known as the Document Object Model (DOM). The purpose of the DOM is to provide an interface for programs to change the structure, style, and content of web pages. The DOM represents the document as nodes and objects. Amongst other things, this allows programming languages to interactively change the page and HTML!*\n",
    ">\n",
    "> *What you'll see is the DOM and HTML create a hierarchy of elements. This structure and the underlying elements can be navigated similarly to a family tree which is one of Beautiful Soup's main mechanisms for navigation. Once you select a specific element within a page, you can then navigate to successive elements using methods to retrieve related tags including a tag's sibling, parent or descendants.*\n",
    ">\n",
    "> *To learn more about the DOM see:*\n",
    "> *https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e6c9b",
   "metadata": {},
   "source": [
    "## Beautiful Soup\n",
    "\n",
    "> *https://www.crummy.com/software/BeautifulSoup/bs4/doc/*\n",
    ">\n",
    "> *Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.*\n",
    "\n",
    "\n",
    "### ***Precaution***\n",
    "\n",
    "> *While web scraping is a powerful tool, it can also lead you into ethical and legal gray areas.*\n",
    "> - *To start, it is possible to make hundreds of requests a second to a website.*\n",
    ">     - *Browsing at superhuman speeds such as this is apt to get noticed. Large volumes of requests such as this are apt to bog down a website's servers and in extreme cases could be considered a denial of service attack.* \n",
    "> - *Similarly, any website requiring login may contain information that is thereby not considered public and scraping said websites could leave you in legal jeopardy.* \n",
    ">\n",
    "> *Use your best judgment when scraping and exercise precautions. Having your IP address blocked from your favorite website, for example, could prove to be quite an annoyance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e3ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T18:50:57.863571Z",
     "start_time": "2021-07-15T18:50:56.911124Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc9f634",
   "metadata": {},
   "source": [
    "### *Pandas Hack - `pd.read_html()`*\n",
    "*Occasionally, there will be a webpage where the information you want is already formatted in a `<table>` in the html. In those cases, Pandas can retrieve the data directly from the URL.*\n",
    "\n",
    "*When used in this way, Pandas returns a list of dataframes that are extracted from tables from the webpage.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e41fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T19:43:54.807224Z",
     "start_time": "2021-07-15T19:43:54.804785Z"
    }
   },
   "outputs": [],
   "source": [
    "# SUMMER_OLYMPICS = 'https://en.wikipedia.org/wiki/Athletics_at_the_1924_Summer_Olympics_%E2%80%93_Men%27s_javelin_throw'\n",
    "# df_lst = pd.read_html(SUMMER_OLYMPICS)\n",
    "# df_lst[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b8801e",
   "metadata": {},
   "source": [
    "# Using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6934d1b",
   "metadata": {},
   "source": [
    "*It's always a good idea to explore the website with:*\n",
    "- *`Right-Click > Inspect` ...*\n",
    "\n",
    "> <a href='https://books.toscrape.com/index.html'>*books.toscrape.com*</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1379c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T18:55:12.962466Z",
     "start_time": "2021-07-15T18:55:12.960166Z"
    }
   },
   "outputs": [],
   "source": [
    "URL = 'https://books.toscrape.com/catalogue/page-1.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2370ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T19:44:05.932104Z",
     "start_time": "2021-07-15T19:44:05.929648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demo of `os.path.split()`. This may come in handy later...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdabf97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T18:57:12.664752Z",
     "start_time": "2021-07-15T18:57:10.657680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demo of `time.sleep()`. This may come in handy later...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb5816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T18:58:45.313280Z",
     "start_time": "2021-07-15T18:58:44.863907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use requests to get the page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae38f2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T18:59:01.316311Z",
     "start_time": "2021-07-15T18:59:01.169586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make soup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b57965",
   "metadata": {},
   "source": [
    "# Practice\n",
    "Our goal is to extract data from this site. We want **a dataframe containing columns: `Title, Stars, Price, In Stock`**.\n",
    "\n",
    "---\n",
    "\n",
    "In order to do this successfully, we need to break this process up into steps which we will put together at the end.\n",
    "\n",
    "***Steps***\n",
    "1. ***Scrape a Single Page***\n",
    "    1. **Capture a single book as a data point.**\n",
    "        - Find how book entries are represented on the site.\n",
    "            - *Using `Inspect` in the browser.*\n",
    "        - Using an example entry, create a function that returns the data in a formatted way for us to use.\n",
    "            - *The book should be thought of as an entry in the dataframe.* \n",
    "            - *How should we encode a row?*\n",
    "        - **Write this in a function.**\n",
    "    2. **Capture all books on a given page.**\n",
    "        - Use the above function to extract *all* the data from a given page.\n",
    "        - **Write this in a function.**\n",
    "\n",
    "\n",
    "2. ***Scrape Multiple Pages***\n",
    "    1. **Find a way to traverse the pages.**\n",
    "        - Rather than hard-coding the url *(which is a reasonable option, but not best-practice)*, we should use the webpage itself to find the url we want to travel to next.\n",
    "        - *What is the \"gotchya\" that we have to avoid for our code to avoid breaking?*\n",
    "        > ***Write a practice script that goes through each page and prints the url or title.***\n",
    "        > \n",
    "        > *Add a short pause between requests using `time.sleep()`.*\n",
    "    \n",
    "2. ***Scrape All Data from All Pages***\n",
    "    > **Write a function that takes a URL and returns a dataframe.**\n",
    "    >\n",
    "    > ```python\n",
    "    > def scrape_books_toscrape(\n",
    "    >         url='https://books.toscrape.com/catalogue/page-1.html', \n",
    "    >         verbose=True):\n",
    "    >     \"\"\"\n",
    "    >     Returns a pandas dataframe with the scraped data from books.toscrape.com\n",
    "    >     \"\"\"\n",
    "    >     \n",
    "    >     return\n",
    "    > ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824443d",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb2560",
   "metadata": {},
   "source": [
    "### 1a. Capture a single book as a data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8eb6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T19:08:51.255355Z",
     "start_time": "2021-07-15T19:08:51.245346Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa025e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T19:13:07.336703Z",
     "start_time": "2021-07-15T19:13:07.331704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b60281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T19:15:39.778234Z",
     "start_time": "2021-07-15T19:15:39.773930Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe88ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T19:23:40.295976Z",
     "start_time": "2021-07-15T19:23:40.291396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350ac1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T19:25:07.040530Z",
     "start_time": "2021-07-15T19:25:07.035889Z"
    }
   },
   "outputs": [],
   "source": [
    "# In Stock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850cbd5",
   "metadata": {},
   "source": [
    "### 1b. Capture all books on a given page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f0342f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T19:29:40.576496Z",
     "start_time": "2021-07-15T19:29:40.574356Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define functions to extract each element from the pods.\n",
    "# - Name\n",
    "# - Stars\n",
    "# - Price\n",
    "# - Instock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c72a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94a097be",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e00c16d",
   "metadata": {},
   "source": [
    "### 2a. Find a way to traverse the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811a66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ae3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c305dc0",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb0d05",
   "metadata": {},
   "source": [
    "### 3a. Write a function that takes a URL and returns a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books_toscrape(\n",
    "        url='https://books.toscrape.com/catalogue/page-1.html', \n",
    "        verbose=True):\n",
    "    \"\"\"\n",
    "    Returns a pandas dataframe with the scraped data from books.toscrape.com\n",
    "    \"\"\"\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4b817",
   "metadata": {},
   "source": [
    "# Further Scraping Tools\n",
    "- <a href='https://www.selenium.dev/'>*Selenium*</a>\n",
    "- <a href='https://scrapy.org/'>*Scrapy*</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "436.009px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
